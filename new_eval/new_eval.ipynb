{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import utils.delexicalize as delex\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "import json\n",
    "from utils.nlp import normalize\n",
    "import sqlite3\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from utils.nlp import BLEUScorer\n",
    "\n",
    "from evaluate import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"test\"\n",
    "evaluator = MultiWozEvaluator(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/test_reference.json\", \"r\") as f:\n",
    "    human_raw_data = json.load(f)\n",
    "human_proc_data = {}\n",
    "for key, value in human_raw_data.items():\n",
    "    human_proc_data[key + '.json'] = value\n",
    "    #human_proc_data[key] = value['sys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT\n",
    "# with open(\"data/test_dials.json\", \"r\") as f:\n",
    "#     human_raw_data = json.load(f)\n",
    "# human_proc_data = {}\n",
    "# for key, value in human_raw_data.items():\n",
    "#     human_proc_data[key] = value['sys']\n",
    "    \n",
    "# HIER\n",
    "prediction_json = \"../running/transformer_hier++/model_turns_greedy_test.json\"\n",
    "with open(prediction_json, \"r\") as f:\n",
    "    human_raw_data = json.load(f)\n",
    "generated_data = {}\n",
    "for key, value in human_raw_data.items():\n",
    "    generated_data[key + '.json'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Corpus Matches : 87.90%\n",
      "test Corpus Success : 84.00%\n",
      "test Corpus BLEU : 0.00%\n",
      "Total number of dialogues: 1000 \n"
     ]
    }
   ],
   "source": [
    "# PROVIDE HERE YOUR GENERATED DIALOGUES INSTEAD\n",
    "# generated_data = human_proc_data\n",
    "# for key, value in human_raw_data.items():\n",
    "#     human_proc_data[key] = value['sys'] # Array of system utterances\n",
    "\n",
    "_, _, _, all_match_success = evaluator.evaluateModel(generated_data, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match and Success stats\n",
    "pred_file = prediction_json.replace(\"model_turns\", \"stats\").replace(\"json\", \"tsv\")\n",
    "all_match_success = pd.DataFrame.from_records(all_match_success)\n",
    "all_match_success.to_csv(pred_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py2)",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
